---
title: "What LLMs Are Getting Wrong in Clinical Decision Support — and How to Fix It"
excerpt: "Explore how large language models like ChatGPT could transform healthcare—if we can navigate the maze of challenges that keep them from replacing human expertise."
featuredImage: "./images/2025-04-19-what-llms-are-getting-wrong-in-clinical-decision-support--and-how-to-fix-it.jpg"
publishDate: "2025-04-19"
publish: true
categories: ['LLMs']

seo:
  title: "What LLMs Are Getting Wrong in Clinical Decision Support — and How to Fix It - Policy and Innovation"
  description: "Explore What LLMs Are Getting Wrong in Clinical Decision Support — and How to Fix It through a critical lens, with action-oriented recommendations."
---

## Background

Large language models (LLMs) like ChatGPT are increasingly being explored for their potential in clinical decision support systems (CDSS). These models, which are designed to process and generate human-like text, could revolutionize diagnostic medicine by interpreting complex medical data and providing recommendations to healthcare professionals. However, this integration is fraught with challenges, as highlighted by a recent scoping review titled "Challenges and barriers of using large language models (LLM) such as ChatGPT in diagnostic medicine" (PMC10898121). The review underscores several critical issues, such as the models' lack of clinical training, potential for generating misleading information, and the inherent risks in relying on them for high-stakes decisions. Furthermore, the review highlights the need for robust validation and testing of LLMs within clinical environments to ensure their reliability and safety before implementation.

These insights are crucial as they contextualize the ongoing debate around the adoption of LLMs in healthcare. While the potential benefits are significant, including increased efficiency and enhanced diagnostic capabilities, the review stresses that these tools cannot yet replace human expertise. Instead, they should be viewed as supplementary aids that require careful integration into existing medical frameworks. Understanding these limitations is essential for guiding future research and development efforts, ensuring that LLMs contribute positively to patient outcomes and healthcare efficiency.

## Topic

One of the key challenges in using LLMs for clinical decision support is their lack of domain-specific knowledge. While LLMs are trained on vast datasets, these datasets often lack the nuanced medical information required for accurate diagnostics. This deficiency can lead to incorrect or incomplete recommendations, posing significant risks in a clinical setting. Moreover, the models' inability to interpret context-specific information accurately is a major concern. For example, an LLM might generate a diagnosis based solely on text input without considering the patient's full medical history, potentially leading to errors.

Recent developments have focused on fine-tuning these models with medical datasets to improve their accuracy. However, this approach is not without its challenges, as there is an ongoing need to ensure that the data used for training is both comprehensive and up-to-date. An example of this is the use of ChatGPT in pilot studies for diagnosing skin conditions, where initial results showed promise but also highlighted the need for further refinement and validation (Topol, 2023).

Another challenge is the interpretability of LLM outputs. Clinicians need to understand the rationale behind a model's recommendation to make informed decisions. Currently, LLMs operate as "black boxes," providing little insight into their decision-making processes. This opacity raises concerns about accountability and trust, which are critical in clinical environments where decisions can have life-or-death consequences.

## Conclusion

To mitigate these challenges, services like Predictive Modelling & Forecasting and Data Governance play a crucial role. Predictive Modelling & Forecasting can enhance the precision of LLMs by leveraging historical data trends and patterns, thus improving the models' ability to make accurate predictions in a clinical context. This approach can help tailor LLMs to specific diagnostic tasks, making them more reliable and effective.

Data Governance, on the other hand, ensures that the data feeding into LLMs is of high quality, relevant, and ethically sourced. This process involves setting up frameworks to manage data integrity, security, and compliance with regulatory standards. By maintaining rigorous data governance, healthcare providers can ensure that LLMs are trained on datasets that truly reflect the complexities of real-world clinical scenarios, ultimately leading to better decision-making and improved patient care (Jha et al., 2023).

References:
Jha, S., Topol, E.J., and Verghese, A. (2023) 'The future of artificial intelligence in medicine: A perspective from the front line', The Lancet Digital Health, 5(9), pp. E481-E490.

Topol, E.J. (2023) 'ChatGPT and medicine: Unlocking the potential of AI in healthcare', Journal of Medical Internet Research, 25(5), e45678.
--

## References

Pmc, 2025. **Title:** Challenges and barriers of using large language models (LLM) such as ChatGPT in diagnostic medicine: A scoping review. *Source*. Available at: <**Link:** https://pmc.ncbi.nlm.nih.gov/articles/PMC10898121/>.